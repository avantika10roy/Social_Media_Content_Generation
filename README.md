<div align="center">

# ğŸ¤– AI-Powered Social Media Content Generation System

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100.0+-009688.svg)](https://fastapi.tiangolo.com)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

*Transform your social media presence with AI-powered content generation*

[Features](#features) â€¢ [Installation](#installation) â€¢ [Documentation](#documentation) â€¢ [Usage](#usage) â€¢ [Contributing](#contributing)

</div>

---

## ğŸŒŸ Overview

The AI-Powered Social Media Content Generation System is a cutting-edge solution that harnesses the power of Large Language Models (LLMs) and Stable Diffusion to revolutionize social media content creation. This system automatically generates platform-specific posts while maintaining brand consistency and engagement quality.

### ğŸ¯ Key Objectives

- Automated, context-aware social media content generation
- Brand-consistent content creation
- Streamlined content workflow optimization
- Cross-platform content adaptation

## âœ¨ Features

### ğŸ¤– Core Capabilities

- **Intelligent Content Generation**
  - Context-aware post creation
  - Platform-specific formatting
  - Brand voice preservation
  - Hashtag optimization

- **Smart Integration**
  - RESTful API
  - Intuitive frontend interface
  - Real-time preview
  - Batch processing support

## ğŸ› ï¸ Technology Stack

### Core Technologies
- Python 3.10+
- PyTorch
- Hugging Face Transformers
- Diffusers
- FastAPI
- Streamlit

### AI Models
- **Text Generation**: LLAMA-7B
- **Caption Generation**: BLIP
- **Image Generation**: Stable Diffusion XL (SDXL)

## ğŸ“‹ Prerequisites

Before you begin using the AI-Powered Social Media Content Generation System, ensure that your environment is properly set up. You will need to install the following tools and libraries:

### System Requirements:
- **Python**: Python 3.10 or later
- **Operating System**: Linux, macOS, or Windows (All platforms supported)

### Software Requirements:
1. **Python** (3.10+): This project is built with Python 3.10 or newer. You can download Python from the official website:
   - [Python Download](https://www.python.org/downloads/)

2. **Chromedriver**: Required for Selenium-based web scraping. It can be installed using the following command (depending on your OS):
   - For **Windows**: Download from [ChromeDriver](https://sites.google.com/a/chromium.org/chromedriver/downloads)
   - For **Linux/macOS**: Install via a package manager or download the appropriate version from the above link.


## ğŸš€ Installation

### Quick Start

```bash
# Clone the repository
git clone https://github.com/satyaki-itobuz/social_media_content_generation.git
cd social_media_content_generation

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```


## ğŸ“ Project Structure

```plaintext
Social_Media_Content_Generation/
â”œâ”€â”€ LICENSE                                # MIT License for the project
â”œâ”€â”€ README.md                              # Executive summary of the project and results
â”œâ”€â”€ base_model_downoader.py                # Downloads SDXL Base Model
â”œâ”€â”€ changelog.txt                          # Contains the description of the changes from the starting and done by whom
â”œâ”€â”€ config                                 # Centralized Configuration module for the whole project
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ credentials
|   â””â”€â”€ client_secret.json
â”œâ”€â”€ data                                   # All type of data in each stage has been saved here
â”‚   â”œâ”€â”€ cleaned_data
â”‚   â”‚   â”œâ”€â”€ facebook_cleaned_data.json     # Cleaned facebook data 
â”‚   â”‚   â”œâ”€â”€ instagram_cleaned_data.json    # Cleaned instagram data
â”‚   â”‚   â””â”€â”€ linkedin_cleaned_data.json     # Cleaned linkedin data
â”‚   â”œâ”€â”€ curated_data                       
â”‚   â”‚   â””â”€â”€ final_data.json                # After merging data from all platforms, saved here in one unified place
â”‚   â”œâ”€â”€ extracted_features_data             
â”‚   â”‚   â”œâ”€â”€ blip_output.json               # Extracted features using BLIP along with original features saved here
|   |   â””â”€â”€ clip_output.json               # Extracted features using CLIP along with original features saved here
|   â”œâ”€â”€ logo_identification_result
|   |   â””â”€â”€ output_with_logo_info_and_uploads.json       # Adds logo position in image
|   â”œâ”€â”€ mixed_curated
|   |   â””â”€â”€ mixed_curated.json             # Adds raw post content
|   â”œâ”€â”€ preprocessed_data
|   |   â”œâ”€â”€ preprocessed_data.json         # Combines all preprocessed features in json format
|   |   â””â”€â”€ preprocessed_data2.json
â”‚   â”œâ”€â”€ raw_data
â”‚   |   â”œâ”€â”€ facebook_raw_data.json         # Raw Scraped facebook data
â”‚   |   â”œâ”€â”€ instagram_raw_data.json        # Raw scraped instagram data
â”‚   |   â””â”€â”€ linkedin_raw_data.json         # Raw scraped linkedin data
|   â””â”€â”€ logo.jpg
â”œâ”€â”€ data_processor.py                       
â”œâ”€â”€ docs                                   # A centralized folder for keeping all project related documents for future purpose
â”‚   â”œâ”€â”€ project_flowchart.png
â”‚   â””â”€â”€ workflow.png
â”œâ”€â”€ logs                                   # Log files saved here for all the tasks
â”œâ”€â”€ llm_evaluation.py                      # Evaluate the performance of LLM
â”œâ”€â”€ llm_modular.py                         # Modular LLM finetuning code
â”œâ”€â”€ llm_run.py                             # LLM Inference
â”œâ”€â”€ notebooks                              # Containing all jupyter notebooks for experimentation
|   â”œâ”€â”€ FLAN-T5.ipynb
â”‚   â””â”€â”€ LLM_Experiments.ipynb
â”œâ”€â”€ requirements.txt                       # Required python dependencies
â”œâ”€â”€ results
|   â”œâ”€â”€ evaluation_results                 # Results of evaluation
|   |   â””â”€â”€ falcon3_1b_instruct_eval.json
|   â””â”€â”€ llm_results
|   |   â”œâ”€â”€ fine_tuning_results_v1/checkpoint-115
|   |   â”œâ”€â”€ flan_t5_base_fine_tuning_results_v1
|   |   â”œâ”€â”€ pipeline_finetuning_v9
|   |   â””â”€â”€ __init__.py
â”œâ”€â”€ run.py                                 # 
â”œâ”€â”€ scrape_raw_data.py                     # Run file for data collection by scraper module
â”œâ”€â”€ setup.sh                               # Project environment setup 
â”œâ”€â”€ src                                    # All source codes 
|   â”œâ”€â”€ custom_dataset                     # Custom dataset for LLM
|   â”‚   â””â”€â”€ llm_dataset.py
|   â”œâ”€â”€ data_cleaner                       # Centralized module for data cleaning for whole project
|   â”‚   â”œâ”€â”€ README.md                      # Clean and preprocess scraped social media content
|   â”‚   â”œâ”€â”€ __init__.py 
|   â”‚   â”œâ”€â”€ image_cleaner.py
|   â”‚   â””â”€â”€ text_cleaner.py
|   â”œâ”€â”€ data_curator                       # Centralized module for data curation for whole project
|   â”‚   â”œâ”€â”€ README.md                      # Merge, refine, and structure cleaned social media data
|   â”‚   â”œâ”€â”€ __init__.py
|   â”‚   â”œâ”€â”€ data_curation.py
|   â”‚   â””â”€â”€ mix_curator.py
|   â”œâ”€â”€ data_preprocessor                  # Centralized module for data preprocessing for whole project
|   â”‚   â”œâ”€â”€ README.md                      # Transform, augment, and standardize both text and image data
|   â”‚   â”œâ”€â”€ __init__.py
|   â”‚   â”œâ”€â”€ image_augmentor.py
|   â”‚   â”œâ”€â”€ llm_finetune_data_preprocessor.py
|   â”‚   â””â”€â”€ text_preprocessing.py
|   â”œâ”€â”€ feature_engineering                # Centralized module for feature engineering for whole project
|   â”‚   â”œâ”€â”€ blip_feature_extraction.py
|   â”‚   â””â”€â”€ clip_feature_extraction.py
|   â”œâ”€â”€ frontend                           # Centralized module for frontend management
|   â”‚   â””â”€â”€ __init__.py
|   â”œâ”€â”€ identify_logo                           
|   â”‚   â””â”€â”€ logo_identification.py
|   â”œâ”€â”€ model_finetuners                   # Model fine-tuning functionalities
|   â”‚   â”œâ”€â”€ __init__.py
|   â”‚   â”œâ”€â”€ flan_t5_finetuner.py
|   â”‚   â”œâ”€â”€ llm_fine_tuner.py
|   â”‚   â””â”€â”€ t5_lora_finetuning.py
|   â”œâ”€â”€ model_inference                    # Model inference functionalities
|   â”‚   â”œâ”€â”€ __init__.py
|   â”‚   â”œâ”€â”€ flan_t5_inference.py
|   â”‚   â”œâ”€â”€ llm_inference.py
|   â”‚   â””â”€â”€ t5_inference.py
|   â”œâ”€â”€ prompts                            # Storing prompts that generate good results
|   â”‚   â””â”€â”€ __init__.py
|   â”‚   â”œâ”€â”€ prompts.py
|   â”œâ”€â”€ scraper                            # Centralized scraper module 
|   â”‚   â”œâ”€â”€ __init__.py
|   â”‚   â”œâ”€â”€ facebook_scraper.py
|   â”‚   â”œâ”€â”€ instagram_scraper.py
|   â”‚   â””â”€â”€ linkedin_scraper.py
|   â”œâ”€â”€ scripts                            # 
|   â”‚   â””â”€â”€ example.sh 
|   â””â”€â”€ utils                              # Unified utility module for any other utilities than model related tasks
|       â”œâ”€â”€ __init__.py
|       â”œâ”€â”€ color_themes.py
|       â”œâ”€â”€ data_saver.py
|       â”œâ”€â”€ download_from_drive.py
|       â”œâ”€â”€ set_seed.py
|       â””â”€â”€ logger.py 
â”œâ”€â”€ T5_run.py 
â””â”€â”€ web_app
    â”œâ”€â”€ assets
    |   â””â”€â”€ logo.png
    â”œâ”€â”€ pages
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ app.py
    â”œâ”€â”€ image_generation_inference.py
    â”œâ”€â”€ pydantic_inputs.py
    â”œâ”€â”€ pydantic_outputs.py
    â”œâ”€â”€ social_media_content_generator.py
    â””â”€â”€ text_generation_inference.py
```

## ğŸ’» Usage

### Model Fine-tuning
```bash 
Yet to be done
```

### API Usage

```bash
# Go to the web folder
cd web/

# Start the API server
uvicorn api.app:app --reload --host 0.0.0.0 --port 8000
```

## ğŸ“Š Performance Metrics

| Metric | Target | Current |
|--------|---------|---------|
| Response Time | <30s | 25s |
| Platform Support | 3+ | 4 |

## ğŸ“š Documentation

Comprehensive documentation is available in the `/docs` directory:

- ğŸ“– [System Architecture](docs/architecture.md)
- ğŸ”§ [API Reference](docs/api.md)
- ğŸ‘¥ [User Guide](docs/user_guide.md)
- ğŸ“ [Fine-tuning Guide](docs/fine-tuning.md)

## ğŸ—ºï¸ Future Roadmap

### Phase 1: Scalability
- [ ] Multi-user support
- [ ] Platform expansion

### Phase 2: Advanced Features
- [ ] Analytics dashboard

### Phase 3: Integrations
- [ ] Direct social media posting


## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- AI-ML-2024 Internship Program Team
- Open-source AI Model Providers:
  - Meta
  - Salesforce

---

<div align="center">

**Made with â¤ï¸ by the AI-ML-2024 Intern Team**

[â†‘ Back to Top](#)

</div>